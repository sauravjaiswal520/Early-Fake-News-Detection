              total        used        free      shared  buff/cache   available
Mem:          92486        1081       90251           1        1153       90792
Swap:             0           0           0
Sat Nov 14 09:32:36 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 418.87.01    Driver Version: 418.87.01    CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:00:07.0 Off |                    0 |
| N/A   34C    P0    38W / 300W |      0MiB / 32480MiB |      1%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
task:  twitter16
{'lr': 0.001, 'reg': 1e-06, 'embeding_size': 100, 'batch_size': 16, 'nb_filters': 100, 'kernel_sizes': [3, 4, 5], 'dropout': 0.5, 'epochs': 18, 'num_classes': 4, 'target_names': ['NR', 'FR', 'TR', 'UR'], 'save_path': 'checkpoint/weights.best.twitter16.pgan', 'maxlen': 50, 'n_heads': 8}
PGAN(
  (word_embedding): Embedding(1364, 300, padding_idx=0)
  (user_embedding): Embedding(1092, 100, padding_idx=0)
  (source_embedding): Embedding(818, 100)
  (convs): ModuleList(
    (0): Conv1d(300, 100, kernel_size=(3,), stride=(1,))
    (1): Conv1d(300, 100, kernel_size=(4,), stride=(1,))
    (2): Conv1d(300, 100, kernel_size=(5,), stride=(1,))
  )
  (max_poolings): ModuleList(
    (0): MaxPool1d(kernel_size=48, stride=48, padding=0, dilation=1, ceil_mode=False)
    (1): MaxPool1d(kernel_size=47, stride=47, padding=0, dilation=1, ceil_mode=False)
    (2): MaxPool1d(kernel_size=46, stride=46, padding=0, dilation=1, ceil_mode=False)
  )
  (linear): Linear(in_features=400, out_features=200, bias=True)
  (dropout): Dropout(p=0.5, inplace=False)
  (relu): ReLU()
  (elu): ELU(alpha=1.0)
  (fc_out): Sequential(
    (0): Linear(in_features=500, out_features=100, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=100, out_features=4, bias=True)
  )
  (fc_user_out): Sequential(
    (0): Linear(in_features=100, out_features=100, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=100, out_features=3, bias=True)
  )
  (fc_ruser_out): Sequential(
    (0): Linear(in_features=100, out_features=100, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=100, out_features=3, bias=True)
  )
)

Epoch  1 / 18
Batch[0] - loss: 3.550266  acc: 43.0000%(7/16)
Batch[1] - loss: 3.611647  acc: 12.0000%(2/16)
Batch[2] - loss: 3.583008  acc: 31.0000%(5/16)
Batch[3] - loss: 3.572760  acc: 18.0000%(3/16)
Batch[4] - loss: 3.630677  acc: 6.0000%(1/16)
Batch[5] - loss: 3.521257  acc: 25.0000%(4/16)
Batch[6] - loss: 3.541488  acc: 31.0000%(5/16)
Batch[7] - loss: 3.536586  acc: 25.0000%(4/16)
Batch[8] - loss: 3.519523  acc: 18.0000%(3/16)
Batch[9] - loss: 3.541364  acc: 6.0000%(1/16)
Batch[10] - loss: 3.469913  acc: 18.0000%(3/16)
Batch[11] - loss: 3.471399  acc: 37.0000%(6/16)
Batch[12] - loss: 3.554827  acc: 12.0000%(2/16)
Batch[13] - loss: 3.543840  acc: 18.0000%(3/16)
Batch[14] - loss: 3.642699  acc: 12.0000%(2/16)
Batch[15] - loss: 3.665774  acc: 18.0000%(3/16)
Batch[16] - loss: 3.465578  acc: 31.0000%(5/16)
Batch[17] - loss: 3.524982  acc: 18.0000%(3/16)
Batch[18] - loss: 3.545911  acc: 31.0000%(5/16)
Batch[19] - loss: 3.382143  acc: 50.0000%(8/16)
Batch[20] - loss: 3.346235  acc: 43.0000%(7/16)
Batch[21] - loss: 3.320406  acc: 43.0000%(7/16)
Batch[22] - loss: 3.403510  acc: 31.0000%(5/16)
Batch[23] - loss: 3.383975  acc: 37.0000%(6/16)
Batch[24] - loss: 3.330087  acc: 25.0000%(4/16)
Batch[25] - loss: 3.268001  acc: 37.0000%(6/16)
Batch[26] - loss: 3.553528  acc: 37.0000%(6/16)
Batch[27] - loss: 3.484223  acc: 25.0000%(4/16)
Batch[28] - loss: 3.411235  acc: 25.0000%(4/16)
Batch[29] - loss: 3.237669  acc: 50.0000%(8/16)
Batch[30] - loss: 3.353079  acc: 31.0000%(5/16)
Batch[31] - loss: 3.356394  acc: 18.0000%(3/16)
Batch[32] - loss: 3.184720  acc: 12.0000%(2/16)
Batch[33] - loss: 2.989542  acc: 43.0000%(7/16)
Batch[34] - loss: 4.257647  acc: 12.0000%(1/8)
Average loss:3.478740 average acc:26.000000%
Val set acc: 0.4146341463414634
Best val set acc: 0

Epoch  2 / 18
Batch[0] - loss: 3.840772  acc: 56.0000%(9/16)
Batch[1] - loss: 3.211374  acc: 56.0000%(9/16)
Batch[2] - loss: 3.116453  acc: 50.0000%(8/16)
Batch[3] - loss: 2.898937  acc: 68.0000%(11/16)
Batch[4] - loss: 2.969525  acc: 43.0000%(7/16)
Batch[5] - loss: 3.071108  acc: 37.0000%(6/16)
Batch[6] - loss: 3.128048  acc: 50.0000%(8/16)
Batch[7] - loss: 2.972968  acc: 50.0000%(8/16)
Batch[8] - loss: 2.927055  acc: 31.0000%(5/16)
Batch[9] - loss: 3.700978  acc: 43.0000%(7/16)
Batch[10] - loss: 2.817168  acc: 43.0000%(7/16)
Batch[11] - loss: 2.906550  acc: 31.0000%(5/16)
Batch[12] - loss: 3.100026  acc: 56.0000%(9/16)
Batch[13] - loss: 3.225408  acc: 43.0000%(7/16)
Batch[14] - loss: 3.521274  acc: 31.0000%(5/16)
Batch[15] - loss: 3.711789  acc: 25.0000%(4/16)
Batch[16] - loss: 2.951471  acc: 68.0000%(11/16)
Batch[17] - loss: 3.679671  acc: 56.0000%(9/16)
Batch[18] - loss: 2.646265  acc: 56.0000%(9/16)
Batch[19] - loss: 3.565787  acc: 43.0000%(7/16)
Batch[20] - loss: 3.345402  acc: 43.0000%(7/16)
Batch[21] - loss: 3.110715  acc: 56.0000%(9/16)
Batch[22] - loss: 2.724843  acc: 68.0000%(11/16)
Batch[23] - loss: 3.111418  acc: 25.0000%(4/16)
Batch[24] - loss: 3.126296  acc: 50.0000%(8/16)
Batch[25] - loss: 3.266807  acc: 50.0000%(8/16)
Batch[26] - loss: 3.267122  acc: 50.0000%(8/16)
Batch[27] - loss: 3.077614  acc: 50.0000%(8/16)
Batch[28] - loss: 3.183956  acc: 43.0000%(7/16)
Batch[29] - loss: 2.839796  acc: 37.0000%(6/16)
Batch[30] - loss: 3.283095  acc: 25.0000%(4/16)
Batch[31] - loss: 3.022839  acc: 50.0000%(8/16)
Batch[32] - loss: 3.064994  acc: 50.0000%(8/16)
Batch[33] - loss: 2.954233  acc: 68.0000%(11/16)
Batch[34] - loss: 2.831914  acc: 62.0000%(5/8)
Average loss:3.147819 average acc:47.000000%
Val set acc: 0.5
Best val set acc: 0

Epoch  3 / 18
Batch[0] - loss: 2.947433  acc: 56.0000%(9/16)
Batch[1] - loss: 2.905335  acc: 62.0000%(10/16)
Batch[2] - loss: 2.625737  acc: 75.0000%(12/16)
Batch[3] - loss: 2.783263  acc: 31.0000%(5/16)
Batch[4] - loss: 2.494226  acc: 87.0000%(14/16)
Batch[5] - loss: 3.179678  acc: 68.0000%(11/16)
Batch[6] - loss: 3.009189  acc: 50.0000%(8/16)
Batch[7] - loss: 2.545510  acc: 68.0000%(11/16)
Batch[8] - loss: 2.518326  acc: 81.0000%(13/16)
Batch[9] - loss: 2.668993  acc: 68.0000%(11/16)
Batch[10] - loss: 2.824713  acc: 56.0000%(9/16)
Batch[11] - loss: 2.449957  acc: 87.0000%(14/16)
Batch[12] - loss: 2.673464  acc: 68.0000%(11/16)
Batch[13] - loss: 2.459239  acc: 68.0000%(11/16)
Batch[14] - loss: 2.702281  acc: 68.0000%(11/16)
Batch[15] - loss: 2.653580  acc: 75.0000%(12/16)
Batch[16] - loss: 2.770189  acc: 56.0000%(9/16)
Batch[17] - loss: 2.545099  acc: 75.0000%(12/16)
Batch[18] - loss: 2.500175  acc: 75.0000%(12/16)
Batch[19] - loss: 2.328842  acc: 87.0000%(14/16)
Batch[20] - loss: 2.891891  acc: 75.0000%(12/16)
Batch[21] - loss: 2.393870  acc: 100.0000%(16/16)
Batch[22] - loss: 2.633836  acc: 62.0000%(10/16)
Batch[23] - loss: 2.408408  acc: 62.0000%(10/16)
Batch[24] - loss: 2.342305  acc: 68.0000%(11/16)
Batch[25] - loss: 2.344967  acc: 68.0000%(11/16)
Batch[26] - loss: 2.317185  acc: 75.0000%(12/16)
Batch[27] - loss: 2.090016  acc: 81.0000%(13/16)
Batch[28] - loss: 2.823080  acc: 50.0000%(8/16)
Batch[29] - loss: 1.970157  acc: 81.0000%(13/16)
Batch[30] - loss: 2.243452  acc: 81.0000%(13/16)
Batch[31] - loss: 2.595641  acc: 68.0000%(11/16)
Batch[32] - loss: 2.436604  acc: 68.0000%(11/16)
Batch[33] - loss: 2.255532  acc: 68.0000%(11/16)
Batch[34] - loss: 2.997840  acc: 50.0000%(4/8)
Average loss:2.580858 average acc:69.000000%
Val set acc: 0.7317073170731707
Best val set acc: 0

Epoch  4 / 18
Batch[0] - loss: 2.230399  acc: 87.0000%(14/16)
Batch[1] - loss: 2.460885  acc: 100.0000%(16/16)
Batch[2] - loss: 2.393134  acc: 81.0000%(13/16)
Batch[3] - loss: 1.990647  acc: 75.0000%(12/16)
Batch[4] - loss: 1.784312  acc: 87.0000%(14/16)
Batch[5] - loss: 1.832031  acc: 93.0000%(15/16)
Batch[6] - loss: 1.710236  acc: 93.0000%(15/16)
Batch[7] - loss: 2.305582  acc: 93.0000%(15/16)
Batch[8] - loss: 1.741193  acc: 93.0000%(15/16)
Batch[9] - loss: 1.937478  acc: 87.0000%(14/16)
Batch[10] - loss: 1.594837  acc: 93.0000%(15/16)
Batch[11] - loss: 1.941950  acc: 87.0000%(14/16)
Batch[12] - loss: 1.816933  acc: 87.0000%(14/16)
Batch[13] - loss: 2.105118  acc: 68.0000%(11/16)
Batch[14] - loss: 1.561901  acc: 87.0000%(14/16)
Batch[15] - loss: 1.685852  acc: 87.0000%(14/16)
Batch[16] - loss: 1.735550  acc: 93.0000%(15/16)
Batch[17] - loss: 1.788255  acc: 93.0000%(15/16)
Batch[18] - loss: 1.892578  acc: 87.0000%(14/16)
Batch[19] - loss: 1.450028  acc: 87.0000%(14/16)
Batch[20] - loss: 1.362732  acc: 100.0000%(16/16)
Batch[21] - loss: 1.612264  acc: 75.0000%(12/16)
Batch[22] - loss: 1.984799  acc: 93.0000%(15/16)
Batch[23] - loss: 1.678654  acc: 81.0000%(13/16)
Batch[24] - loss: 1.431792  acc: 87.0000%(14/16)
Batch[25] - loss: 1.391737  acc: 81.0000%(13/16)
Batch[26] - loss: 2.250382  acc: 93.0000%(15/16)
Batch[27] - loss: 1.241408  acc: 93.0000%(15/16)
Batch[28] - loss: 1.116994  acc: 100.0000%(16/16)
Batch[29] - loss: 1.023031  acc: 100.0000%(16/16)
Batch[30] - loss: 1.104781  acc: 87.0000%(14/16)
Batch[31] - loss: 1.661045  acc: 100.0000%(16/16)
Batch[32] - loss: 1.690153  acc: 93.0000%(15/16)
Batch[33] - loss: 1.962457  acc: 81.0000%(13/16)
Batch[34] - loss: 1.405804  acc: 100.0000%(8/8)
Average loss:1.739341 average acc:89.000000%
Val set acc: 0.7439024390243902
Best val set acc: 0

Epoch  5 / 18
Batch[0] - loss: 1.244347  acc: 93.0000%(15/16)
Batch[1] - loss: 1.170805  acc: 100.0000%(16/16)
Batch[2] - loss: 1.711437  acc: 87.0000%(14/16)
Batch[3] - loss: 1.363476  acc: 100.0000%(16/16)
Batch[4] - loss: 1.357613  acc: 93.0000%(15/16)
Batch[5] - loss: 1.045468  acc: 100.0000%(16/16)
Batch[6] - loss: 1.444053  acc: 93.0000%(15/16)
Batch[7] - loss: 0.877906  acc: 100.0000%(16/16)
Batch[8] - loss: 1.213935  acc: 100.0000%(16/16)
Batch[9] - loss: 1.459556  acc: 75.0000%(12/16)
Batch[10] - loss: 1.074958  acc: 93.0000%(15/16)
Batch[11] - loss: 1.544186  acc: 93.0000%(15/16)
Batch[12] - loss: 1.151775  acc: 100.0000%(16/16)
Batch[13] - loss: 0.843290  acc: 100.0000%(16/16)
Batch[14] - loss: 0.995034  acc: 87.0000%(14/16)
Batch[15] - loss: 1.237269  acc: 87.0000%(14/16)
Batch[16] - loss: 1.014967  acc: 93.0000%(15/16)
Batch[17] - loss: 0.960823  acc: 93.0000%(15/16)
Batch[18] - loss: 0.944186  acc: 93.0000%(15/16)
Batch[19] - loss: 0.922964  acc: 100.0000%(16/16)
Batch[20] - loss: 0.804169  acc: 100.0000%(16/16)
Batch[21] - loss: 1.143520  acc: 93.0000%(15/16)
Batch[22] - loss: 1.496399  acc: 100.0000%(16/16)
Batch[23] - loss: 0.963328  acc: 93.0000%(15/16)
Batch[24] - loss: 1.070776  acc: 93.0000%(15/16)
Batch[25] - loss: 1.042288  acc: 93.0000%(15/16)
Batch[26] - loss: 0.668318  acc: 100.0000%(16/16)
Batch[27] - loss: 0.844144  acc: 100.0000%(16/16)
Batch[28] - loss: 0.494105  acc: 100.0000%(16/16)
Batch[29] - loss: 0.693068  acc: 100.0000%(16/16)
Batch[30] - loss: 0.795202  acc: 87.0000%(14/16)
Batch[31] - loss: 1.295375  acc: 100.0000%(16/16)
Batch[32] - loss: 1.523934  acc: 100.0000%(16/16)
Batch[33] - loss: 1.409726  acc: 100.0000%(16/16)
Batch[34] - loss: 0.592823  acc: 100.0000%(8/8)
Average loss:1.097578 average acc:95.000000%
Val set acc: 0.7804878048780488
Best val set acc: 0

Epoch  6 / 18
Batch[0] - loss: 0.844291  acc: 100.0000%(16/16)
Batch[1] - loss: 0.817756  acc: 93.0000%(15/16)
Batch[2] - loss: 0.634500  acc: 93.0000%(15/16)
Batch[3] - loss: 0.957124  acc: 93.0000%(15/16)
Batch[4] - loss: 0.720000  acc: 100.0000%(16/16)
Batch[5] - loss: 0.588198  acc: 100.0000%(16/16)
Batch[6] - loss: 0.543613  acc: 100.0000%(16/16)
Batch[7] - loss: 0.549024  acc: 100.0000%(16/16)
Batch[8] - loss: 1.165559  acc: 100.0000%(16/16)
Batch[9] - loss: 0.901932  acc: 100.0000%(16/16)
Batch[10] - loss: 0.567052  acc: 100.0000%(16/16)
Batch[11] - loss: 0.585148  acc: 100.0000%(16/16)
Batch[12] - loss: 0.646585  acc: 100.0000%(16/16)
Batch[13] - loss: 0.501932  acc: 100.0000%(16/16)
Batch[14] - loss: 0.497568  acc: 100.0000%(16/16)
Batch[15] - loss: 0.527610  acc: 100.0000%(16/16)
Batch[16] - loss: 0.910657  acc: 100.0000%(16/16)
Batch[17] - loss: 0.683195  acc: 100.0000%(16/16)
Batch[18] - loss: 0.632856  acc: 100.0000%(16/16)
Batch[19] - loss: 0.738885  acc: 93.0000%(15/16)
Batch[20] - loss: 0.429929  acc: 100.0000%(16/16)
Batch[21] - loss: 0.629215  acc: 93.0000%(15/16)
Batch[22] - loss: 0.823589  acc: 100.0000%(16/16)
Batch[23] - loss: 0.280465  acc: 93.0000%(15/16)
Batch[24] - loss: 0.712052  acc: 100.0000%(16/16)
Batch[25] - loss: 0.498832  acc: 100.0000%(16/16)
Batch[26] - loss: 0.875198  acc: 87.0000%(14/16)
Batch[27] - loss: 0.497706  acc: 100.0000%(16/16)
Batch[28] - loss: 0.649645  acc: 100.0000%(16/16)
Batch[29] - loss: 0.326971  acc: 100.0000%(16/16)
Batch[30] - loss: 0.554827  acc: 93.0000%(15/16)
Batch[31] - loss: 0.576929  acc: 100.0000%(16/16)
Batch[32] - loss: 0.346041  acc: 100.0000%(16/16)
Batch[33] - loss: 0.433241  acc: 93.0000%(15/16)
Batch[34] - loss: 0.455978  acc: 100.0000%(8/8)
Average loss:0.631546 average acc:98.000000%
Val set acc: 0.8048780487804879
Best val set acc: 0

Epoch  7 / 18
Batch[0] - loss: 0.424003  acc: 100.0000%(16/16)
Batch[1] - loss: 0.537760  acc: 100.0000%(16/16)
Batch[2] - loss: 0.384643  acc: 100.0000%(16/16)
Batch[3] - loss: 0.380716  acc: 100.0000%(16/16)
Batch[4] - loss: 0.347372  acc: 100.0000%(16/16)
Batch[5] - loss: 0.236251  acc: 100.0000%(16/16)
Batch[6] - loss: 0.497302  acc: 100.0000%(16/16)
Batch[7] - loss: 0.162253  acc: 100.0000%(16/16)
Batch[8] - loss: 0.283791  acc: 100.0000%(16/16)
Batch[9] - loss: 0.354122  acc: 100.0000%(16/16)
Batch[10] - loss: 0.392036  acc: 100.0000%(16/16)
Batch[11] - loss: 0.392305  acc: 100.0000%(16/16)
Batch[12] - loss: 0.355435  acc: 100.0000%(16/16)
Batch[13] - loss: 0.352422  acc: 100.0000%(16/16)
Batch[14] - loss: 0.375031  acc: 100.0000%(16/16)
Batch[15] - loss: 0.239577  acc: 100.0000%(16/16)
Batch[16] - loss: 0.158430  acc: 100.0000%(16/16)
Batch[17] - loss: 0.552271  acc: 100.0000%(16/16)
Batch[18] - loss: 0.337452  acc: 100.0000%(16/16)
Batch[19] - loss: 0.534744  acc: 93.0000%(15/16)
Batch[20] - loss: 0.456527  acc: 100.0000%(16/16)
Batch[21] - loss: 0.623238  acc: 100.0000%(16/16)
Batch[22] - loss: 0.511315  acc: 100.0000%(16/16)
Batch[23] - loss: 0.305502  acc: 100.0000%(16/16)
Batch[24] - loss: 0.677888  acc: 100.0000%(16/16)
Batch[25] - loss: 0.394841  acc: 93.0000%(15/16)
Batch[26] - loss: 0.588671  acc: 100.0000%(16/16)
Batch[27] - loss: 0.373183  acc: 100.0000%(16/16)
Batch[28] - loss: 0.253590  acc: 100.0000%(16/16)
Batch[29] - loss: 0.503125  acc: 100.0000%(16/16)
Batch[30] - loss: 0.296880  acc: 100.0000%(16/16)
Batch[31] - loss: 0.182435  acc: 100.0000%(16/16)
Batch[32] - loss: 0.539588  acc: 100.0000%(16/16)
Batch[33] - loss: 0.178036  acc: 100.0000%(16/16)
Batch[34] - loss: 0.339662  acc: 100.0000%(8/8)
Average loss:0.386354 average acc:99.000000%
Val set acc: 0.8292682926829268
Best val set acc: 0

Epoch  8 / 18
Batch[0] - loss: 0.247473  acc: 100.0000%(16/16)
Batch[1] - loss: 0.319924  acc: 100.0000%(16/16)
Batch[2] - loss: 0.224126  acc: 100.0000%(16/16)
Batch[3] - loss: 0.137077  acc: 100.0000%(16/16)
Batch[4] - loss: 0.426474  acc: 100.0000%(16/16)
Batch[5] - loss: 0.276071  acc: 100.0000%(16/16)
Batch[6] - loss: 0.170311  acc: 100.0000%(16/16)
Batch[7] - loss: 0.194118  acc: 100.0000%(16/16)
Batch[8] - loss: 0.158744  acc: 100.0000%(16/16)
Batch[9] - loss: 0.160342  acc: 100.0000%(16/16)
Batch[10] - loss: 0.174658  acc: 100.0000%(16/16)
Batch[11] - loss: 0.243571  acc: 100.0000%(16/16)
Batch[12] - loss: 0.373365  acc: 93.0000%(15/16)
Batch[13] - loss: 0.206611  acc: 100.0000%(16/16)
Batch[14] - loss: 0.155992  acc: 100.0000%(16/16)
Batch[15] - loss: 0.479099  acc: 100.0000%(16/16)
Batch[16] - loss: 0.252724  acc: 100.0000%(16/16)
Batch[17] - loss: 0.358975  acc: 100.0000%(16/16)
Batch[18] - loss: 0.141258  acc: 100.0000%(16/16)
Batch[19] - loss: 0.347169  acc: 100.0000%(16/16)
Batch[20] - loss: 0.255780  acc: 93.0000%(15/16)
Batch[21] - loss: 0.216352  acc: 100.0000%(16/16)
Batch[22] - loss: 0.180573  acc: 100.0000%(16/16)
Batch[23] - loss: 0.293053  acc: 100.0000%(16/16)
Batch[24] - loss: 0.183872  acc: 100.0000%(16/16)
Batch[25] - loss: 0.180952  acc: 100.0000%(16/16)
Batch[26] - loss: 0.082351  acc: 100.0000%(16/16)
Batch[27] - loss: 0.310582  acc: 100.0000%(16/16)
Batch[28] - loss: 0.188295  acc: 100.0000%(16/16)
Batch[29] - loss: 0.253079  acc: 100.0000%(16/16)
Batch[30] - loss: 0.244529  acc: 100.0000%(16/16)
Batch[31] - loss: 0.139301  acc: 100.0000%(16/16)
Batch[32] - loss: 0.345714  acc: 93.0000%(15/16)
Batch[33] - loss: 0.526639  acc: 93.0000%(15/16)
Batch[34] - loss: 0.101043  acc: 100.0000%(8/8)
Average loss:0.244291 average acc:99.000000%
Val set acc: 0.8414634146341463
Best val set acc: 0

Epoch  9 / 18
Batch[0] - loss: 0.140649  acc: 100.0000%(16/16)
Batch[1] - loss: 0.174728  acc: 100.0000%(16/16)
Batch[2] - loss: 0.272277  acc: 100.0000%(16/16)
Batch[3] - loss: 0.294722  acc: 100.0000%(16/16)
Batch[4] - loss: 0.173119  acc: 100.0000%(16/16)
Batch[5] - loss: 0.234063  acc: 93.0000%(15/16)
Batch[6] - loss: 0.104828  acc: 100.0000%(16/16)
Batch[7] - loss: 0.188507  acc: 100.0000%(16/16)
Batch[8] - loss: 0.069438  acc: 100.0000%(16/16)
Batch[9] - loss: 0.147737  acc: 93.0000%(15/16)
Batch[10] - loss: 0.181130  acc: 100.0000%(16/16)
Batch[11] - loss: 0.166569  acc: 100.0000%(16/16)
Batch[12] - loss: 0.151375  acc: 100.0000%(16/16)
Batch[13] - loss: 0.103453  acc: 100.0000%(16/16)
Batch[14] - loss: 0.190074  acc: 100.0000%(16/16)
Batch[15] - loss: 0.138435  acc: 100.0000%(16/16)
Batch[16] - loss: 0.061896  acc: 100.0000%(16/16)
Batch[17] - loss: 0.107225  acc: 100.0000%(16/16)
Batch[18] - loss: 0.080802  acc: 100.0000%(16/16)
Batch[19] - loss: 0.250884  acc: 100.0000%(16/16)
Batch[20] - loss: 0.101695  acc: 100.0000%(16/16)
Batch[21] - loss: 0.058748  acc: 100.0000%(16/16)
Batch[22] - loss: 0.084359  acc: 100.0000%(16/16)
Batch[23] - loss: 0.196031  acc: 100.0000%(16/16)
Batch[24] - loss: 0.136962  acc: 100.0000%(16/16)
Batch[25] - loss: 0.058667  acc: 100.0000%(16/16)
Batch[26] - loss: 0.121411  acc: 100.0000%(16/16)
Batch[27] - loss: 0.077651  acc: 100.0000%(16/16)
Batch[28] - loss: 0.091864  acc: 100.0000%(16/16)
Batch[29] - loss: 0.157209  acc: 100.0000%(16/16)
Batch[30] - loss: 0.085783  acc: 100.0000%(16/16)
Batch[31] - loss: 0.185170  acc: 93.0000%(15/16)
Batch[32] - loss: 0.098618  acc: 100.0000%(16/16)
Batch[33] - loss: 0.059348  acc: 100.0000%(16/16)
Batch[34] - loss: 0.137623  acc: 100.0000%(8/8)
Average loss:0.139516 average acc:99.000000%
Val set acc: 0.8414634146341463
Best val set acc: 0
              precision    recall  f1-score   support

          NR    0.85000   0.85000   0.85000        20
          FR    0.88235   0.71429   0.78947        21
          TR    0.76923   1.00000   0.86957        20
          UR    0.89474   0.80952   0.85000        21

    accuracy                        0.84146        82
   macro avg    0.84908   0.84345   0.83976        82
weighted avg    0.85004   0.84146   0.83927        82

save model!!!

Epoch  10 / 18
Batch[0] - loss: 0.099547  acc: 100.0000%(16/16)
Batch[1] - loss: 0.131836  acc: 100.0000%(16/16)
Batch[2] - loss: 0.153157  acc: 100.0000%(16/16)
Batch[3] - loss: 0.055032  acc: 100.0000%(16/16)
Batch[4] - loss: 0.051011  acc: 100.0000%(16/16)
Batch[5] - loss: 0.130054  acc: 100.0000%(16/16)
Batch[6] - loss: 0.053340  acc: 100.0000%(16/16)
Batch[7] - loss: 0.099506  acc: 100.0000%(16/16)
Batch[8] - loss: 0.150395  acc: 100.0000%(16/16)
Batch[9] - loss: 0.127893  acc: 100.0000%(16/16)
Batch[10] - loss: 0.111599  acc: 100.0000%(16/16)
Batch[11] - loss: 0.096666  acc: 100.0000%(16/16)
Batch[12] - loss: 0.073412  acc: 100.0000%(16/16)
Batch[13] - loss: 0.064129  acc: 100.0000%(16/16)
Batch[14] - loss: 0.109284  acc: 100.0000%(16/16)
Batch[15] - loss: 0.095446  acc: 100.0000%(16/16)
Batch[16] - loss: 0.051125  acc: 100.0000%(16/16)
Batch[17] - loss: 0.018830  acc: 100.0000%(16/16)
Batch[18] - loss: 0.130448  acc: 100.0000%(16/16)
Batch[19] - loss: 0.040024  acc: 100.0000%(16/16)
Batch[20] - loss: 0.058059  acc: 100.0000%(16/16)
Batch[21] - loss: 0.098887  acc: 93.0000%(15/16)
Batch[22] - loss: 0.136154  acc: 100.0000%(16/16)
Batch[23] - loss: 0.044491  acc: 100.0000%(16/16)
Batch[24] - loss: 0.032969  acc: 100.0000%(16/16)
Batch[25] - loss: 0.095610  acc: 100.0000%(16/16)
Batch[26] - loss: 0.036100  acc: 100.0000%(16/16)
Batch[27] - loss: 0.076695  acc: 100.0000%(16/16)
Batch[28] - loss: 0.078752  acc: 100.0000%(16/16)
Batch[29] - loss: 0.080017  acc: 100.0000%(16/16)
Batch[30] - loss: 0.251377  acc: 100.0000%(16/16)
Batch[31] - loss: 0.083321  acc: 100.0000%(16/16)
Batch[32] - loss: 0.074505  acc: 100.0000%(16/16)
Batch[33] - loss: 0.106384  acc: 100.0000%(16/16)
Batch[34] - loss: 0.053739  acc: 100.0000%(8/8)
Average loss:0.089994 average acc:99.000000%
Val set acc: 0.8048780487804879
Best val set acc: 0.8414634146341463

Epoch  11 / 18
Batch[0] - loss: 0.125470  acc: 100.0000%(16/16)
Batch[1] - loss: 0.060497  acc: 100.0000%(16/16)
Batch[2] - loss: 0.085898  acc: 100.0000%(16/16)
Batch[3] - loss: 0.050372  acc: 100.0000%(16/16)
Batch[4] - loss: 0.049915  acc: 100.0000%(16/16)
Batch[5] - loss: 0.059662  acc: 100.0000%(16/16)
Batch[6] - loss: 0.098097  acc: 100.0000%(16/16)
Batch[7] - loss: 0.073028  acc: 100.0000%(16/16)
Batch[8] - loss: 0.113109  acc: 100.0000%(16/16)
Batch[9] - loss: 0.027608  acc: 100.0000%(16/16)
Batch[10] - loss: 0.039624  acc: 100.0000%(16/16)
Batch[11] - loss: 0.029521  acc: 100.0000%(16/16)
Batch[12] - loss: 0.020147  acc: 100.0000%(16/16)
Batch[13] - loss: 0.063290  acc: 100.0000%(16/16)
Batch[14] - loss: 0.039917  acc: 100.0000%(16/16)
Batch[15] - loss: 0.078315  acc: 100.0000%(16/16)
Batch[16] - loss: 0.066638  acc: 100.0000%(16/16)
Batch[17] - loss: 0.076080  acc: 100.0000%(16/16)
Batch[18] - loss: 0.094706  acc: 100.0000%(16/16)
Batch[19] - loss: 0.103824  acc: 100.0000%(16/16)
Batch[20] - loss: 0.033131  acc: 100.0000%(16/16)
Batch[21] - loss: 0.073151  acc: 100.0000%(16/16)
Batch[22] - loss: 0.064428  acc: 100.0000%(16/16)
Batch[23] - loss: 0.038715  acc: 100.0000%(16/16)
Batch[24] - loss: 0.070878  acc: 100.0000%(16/16)
Batch[25] - loss: 0.036370  acc: 100.0000%(16/16)
Batch[26] - loss: 0.020403  acc: 100.0000%(16/16)
Batch[27] - loss: 0.035131  acc: 100.0000%(16/16)
Batch[28] - loss: 0.063196  acc: 100.0000%(16/16)
Batch[29] - loss: 0.010437  acc: 100.0000%(16/16)
Batch[30] - loss: 0.022017  acc: 100.0000%(16/16)
Batch[31] - loss: 0.074949  acc: 100.0000%(16/16)
Batch[32] - loss: 0.101809  acc: 100.0000%(16/16)
Batch[33] - loss: 0.046008  acc: 100.0000%(16/16)
Batch[34] - loss: 0.052257  acc: 100.0000%(8/8)
Average loss:0.059960 average acc:100.000000%
Val set acc: 0.8048780487804879
Best val set acc: 0.8414634146341463

Epoch  12 / 18
Batch[0] - loss: 0.030862  acc: 100.0000%(16/16)
Batch[1] - loss: 0.038684  acc: 100.0000%(16/16)
Batch[2] - loss: 0.031990  acc: 100.0000%(16/16)
Batch[3] - loss: 0.040574  acc: 100.0000%(16/16)
Batch[4] - loss: 0.044692  acc: 100.0000%(16/16)
Batch[5] - loss: 0.023696  acc: 100.0000%(16/16)
Batch[6] - loss: 0.035397  acc: 100.0000%(16/16)
Batch[7] - loss: 0.051730  acc: 100.0000%(16/16)
Batch[8] - loss: 0.021209  acc: 100.0000%(16/16)
Batch[9] - loss: 0.074478  acc: 100.0000%(16/16)
Batch[10] - loss: 0.044721  acc: 100.0000%(16/16)
Batch[11] - loss: 0.082375  acc: 100.0000%(16/16)
Batch[12] - loss: 0.040424  acc: 100.0000%(16/16)
Batch[13] - loss: 0.034133  acc: 100.0000%(16/16)
Batch[14] - loss: 0.030663  acc: 100.0000%(16/16)
Batch[15] - loss: 0.028297  acc: 100.0000%(16/16)
Batch[16] - loss: 0.094614  acc: 100.0000%(16/16)
Batch[17] - loss: 0.020307  acc: 100.0000%(16/16)
Batch[18] - loss: 0.083571  acc: 100.0000%(16/16)
Batch[19] - loss: 0.028365  acc: 100.0000%(16/16)
Batch[20] - loss: 0.011240  acc: 100.0000%(16/16)
Batch[21] - loss: 0.032438  acc: 100.0000%(16/16)
Batch[22] - loss: 0.027979  acc: 100.0000%(16/16)
Batch[23] - loss: 0.021440  acc: 100.0000%(16/16)
Batch[24] - loss: 0.025874  acc: 100.0000%(16/16)
Batch[25] - loss: 0.028198  acc: 100.0000%(16/16)
Batch[26] - loss: 0.040727  acc: 100.0000%(16/16)
Batch[27] - loss: 0.025817  acc: 100.0000%(16/16)
Batch[28] - loss: 0.061316  acc: 100.0000%(16/16)
Batch[29] - loss: 0.051960  acc: 100.0000%(16/16)
Batch[30] - loss: 0.020307  acc: 100.0000%(16/16)
Batch[31] - loss: 0.041412  acc: 100.0000%(16/16)
Batch[32] - loss: 0.018999  acc: 100.0000%(16/16)
Batch[33] - loss: 0.021011  acc: 100.0000%(16/16)
Batch[34] - loss: 0.009438  acc: 100.0000%(8/8)
Average loss:0.037684 average acc:100.000000%
Val set acc: 0.8048780487804879
Best val set acc: 0.8414634146341463

Epoch  13 / 18
Batch[0] - loss: 0.079342  acc: 100.0000%(16/16)
Batch[1] - loss: 0.026460  acc: 100.0000%(16/16)
Batch[2] - loss: 0.053101  acc: 100.0000%(16/16)
Batch[3] - loss: 0.012404  acc: 100.0000%(16/16)
Batch[4] - loss: 0.041568  acc: 100.0000%(16/16)
Batch[5] - loss: 0.022067  acc: 100.0000%(16/16)
Batch[6] - loss: 0.011871  acc: 100.0000%(16/16)
Batch[7] - loss: 0.038640  acc: 100.0000%(16/16)
Batch[8] - loss: 0.030442  acc: 100.0000%(16/16)
Batch[9] - loss: 0.021142  acc: 100.0000%(16/16)
Batch[10] - loss: 0.050058  acc: 100.0000%(16/16)
Batch[11] - loss: 0.022845  acc: 100.0000%(16/16)
Batch[12] - loss: 0.060473  acc: 100.0000%(16/16)
Batch[13] - loss: 0.015638  acc: 100.0000%(16/16)
Batch[14] - loss: 0.045348  acc: 100.0000%(16/16)
Batch[15] - loss: 0.073355  acc: 100.0000%(16/16)
Batch[16] - loss: 0.020050  acc: 100.0000%(16/16)
Batch[17] - loss: 0.037261  acc: 100.0000%(16/16)
Batch[18] - loss: 0.012803  acc: 100.0000%(16/16)
Batch[19] - loss: 0.025678  acc: 100.0000%(16/16)
Batch[20] - loss: 0.063960  acc: 100.0000%(16/16)
Batch[21] - loss: 0.041856  acc: 100.0000%(16/16)
Batch[22] - loss: 0.084541  acc: 100.0000%(16/16)
Batch[23] - loss: 0.021001  acc: 100.0000%(16/16)
Batch[24] - loss: 0.029600  acc: 100.0000%(16/16)
Batch[25] - loss: 0.017551  acc: 100.0000%(16/16)
Batch[26] - loss: 0.025916  acc: 100.0000%(16/16)
Batch[27] - loss: 0.016966  acc: 100.0000%(16/16)
Batch[28] - loss: 0.044764  acc: 100.0000%(16/16)
Batch[29] - loss: 0.028326  acc: 100.0000%(16/16)
Batch[30] - loss: 0.011726  acc: 100.0000%(16/16)
Batch[31] - loss: 0.037494  acc: 100.0000%(16/16)
Batch[32] - loss: 0.031808  acc: 100.0000%(16/16)
Batch[33] - loss: 0.010813  acc: 100.0000%(16/16)
Batch[34] - loss: 0.007868  acc: 100.0000%(8/8)
Average loss:0.033564 average acc:100.000000%
Reload the best model...
0.0005
Val set acc: 0.8414634146341463
Best val set acc: 0.8414634146341463

Epoch  14 / 18
Batch[0] - loss: 0.053941  acc: 100.0000%(16/16)
Batch[1] - loss: 0.109497  acc: 100.0000%(16/16)
Batch[2] - loss: 0.073583  acc: 100.0000%(16/16)
Batch[3] - loss: 0.087087  acc: 100.0000%(16/16)
Batch[4] - loss: 0.127532  acc: 100.0000%(16/16)
Batch[5] - loss: 0.121645  acc: 100.0000%(16/16)
Batch[6] - loss: 0.087827  acc: 100.0000%(16/16)
Batch[7] - loss: 0.148865  acc: 100.0000%(16/16)
Batch[8] - loss: 0.053717  acc: 100.0000%(16/16)
Batch[9] - loss: 0.079673  acc: 100.0000%(16/16)
Batch[10] - loss: 0.062576  acc: 100.0000%(16/16)
Batch[11] - loss: 0.035647  acc: 100.0000%(16/16)
Batch[12] - loss: 0.076609  acc: 100.0000%(16/16)
Batch[13] - loss: 0.190233  acc: 100.0000%(16/16)
Batch[14] - loss: 0.048482  acc: 100.0000%(16/16)
Batch[15] - loss: 0.210635  acc: 93.0000%(15/16)
Batch[16] - loss: 0.135121  acc: 93.0000%(15/16)
Batch[17] - loss: 0.100802  acc: 100.0000%(16/16)
Batch[18] - loss: 0.116218  acc: 100.0000%(16/16)
Batch[19] - loss: 0.103593  acc: 100.0000%(16/16)
Batch[20] - loss: 0.111459  acc: 100.0000%(16/16)
Batch[21] - loss: 0.031126  acc: 100.0000%(16/16)
Batch[22] - loss: 0.171522  acc: 100.0000%(16/16)
Batch[23] - loss: 0.187570  acc: 100.0000%(16/16)
Batch[24] - loss: 0.101312  acc: 100.0000%(16/16)
Batch[25] - loss: 0.132742  acc: 93.0000%(15/16)
Batch[26] - loss: 0.068986  acc: 100.0000%(16/16)
Batch[27] - loss: 0.091404  acc: 100.0000%(16/16)
Batch[28] - loss: 0.089557  acc: 100.0000%(16/16)
Batch[29] - loss: 0.117787  acc: 100.0000%(16/16)
Batch[30] - loss: 0.049228  acc: 100.0000%(16/16)
Batch[31] - loss: 0.096965  acc: 100.0000%(16/16)
Batch[32] - loss: 0.037379  acc: 100.0000%(16/16)
Batch[33] - loss: 0.076756  acc: 100.0000%(16/16)
Batch[34] - loss: 0.059139  acc: 100.0000%(8/8)
Average loss:0.098463 average acc:99.000000%
Val set acc: 0.8048780487804879
Best val set acc: 0.8414634146341463

Epoch  15 / 18
Batch[0] - loss: 0.090709  acc: 100.0000%(16/16)
Batch[1] - loss: 0.114560  acc: 100.0000%(16/16)
Batch[2] - loss: 0.120775  acc: 93.0000%(15/16)
Batch[3] - loss: 0.045033  acc: 100.0000%(16/16)
Batch[4] - loss: 0.024924  acc: 100.0000%(16/16)
Batch[5] - loss: 0.055242  acc: 100.0000%(16/16)
Batch[6] - loss: 0.030282  acc: 100.0000%(16/16)
Batch[7] - loss: 0.082055  acc: 100.0000%(16/16)
Batch[8] - loss: 0.073442  acc: 100.0000%(16/16)
Batch[9] - loss: 0.056047  acc: 100.0000%(16/16)
Batch[10] - loss: 0.040815  acc: 100.0000%(16/16)
Batch[11] - loss: 0.136372  acc: 100.0000%(16/16)
Batch[12] - loss: 0.144934  acc: 100.0000%(16/16)
Batch[13] - loss: 0.048841  acc: 100.0000%(16/16)
Batch[14] - loss: 0.020492  acc: 100.0000%(16/16)
Batch[15] - loss: 0.100313  acc: 100.0000%(16/16)
Batch[16] - loss: 0.051776  acc: 100.0000%(16/16)
Batch[17] - loss: 0.053666  acc: 100.0000%(16/16)
Batch[18] - loss: 0.047090  acc: 100.0000%(16/16)
Batch[19] - loss: 0.078609  acc: 100.0000%(16/16)
Batch[20] - loss: 0.077441  acc: 100.0000%(16/16)
Batch[21] - loss: 0.078485  acc: 100.0000%(16/16)
Batch[22] - loss: 0.089454  acc: 100.0000%(16/16)
Batch[23] - loss: 0.109310  acc: 100.0000%(16/16)
Batch[24] - loss: 0.119099  acc: 100.0000%(16/16)
Batch[25] - loss: 0.127633  acc: 100.0000%(16/16)
Batch[26] - loss: 0.050426  acc: 100.0000%(16/16)
Batch[27] - loss: 0.052603  acc: 100.0000%(16/16)
Batch[28] - loss: 0.056586  acc: 100.0000%(16/16)
Batch[29] - loss: 0.032968  acc: 100.0000%(16/16)
Batch[30] - loss: 0.055847  acc: 100.0000%(16/16)
Batch[31] - loss: 0.075216  acc: 100.0000%(16/16)
Batch[32] - loss: 0.055035  acc: 100.0000%(16/16)
Batch[33] - loss: 0.060956  acc: 100.0000%(16/16)
Batch[34] - loss: 0.021317  acc: 100.0000%(8/8)
Average loss:0.070810 average acc:99.000000%
Val set acc: 0.8170731707317073
Best val set acc: 0.8414634146341463

Epoch  16 / 18
Batch[0] - loss: 0.078609  acc: 100.0000%(16/16)
Batch[1] - loss: 0.080011  acc: 100.0000%(16/16)
Batch[2] - loss: 0.026604  acc: 100.0000%(16/16)
Batch[3] - loss: 0.049928  acc: 100.0000%(16/16)
Batch[4] - loss: 0.043622  acc: 100.0000%(16/16)
Batch[5] - loss: 0.046259  acc: 100.0000%(16/16)
Batch[6] - loss: 0.073747  acc: 100.0000%(16/16)
Batch[7] - loss: 0.080279  acc: 100.0000%(16/16)
Batch[8] - loss: 0.026409  acc: 100.0000%(16/16)
Batch[9] - loss: 0.045287  acc: 100.0000%(16/16)
Batch[10] - loss: 0.055917  acc: 100.0000%(16/16)
Batch[11] - loss: 0.041615  acc: 100.0000%(16/16)
Batch[12] - loss: 0.064351  acc: 100.0000%(16/16)
Batch[13] - loss: 0.037102  acc: 100.0000%(16/16)
Batch[14] - loss: 0.103569  acc: 100.0000%(16/16)
Batch[15] - loss: 0.064955  acc: 100.0000%(16/16)
Batch[16] - loss: 0.036297  acc: 100.0000%(16/16)
Batch[17] - loss: 0.134223  acc: 100.0000%(16/16)
Batch[18] - loss: 0.029679  acc: 100.0000%(16/16)
Batch[19] - loss: 0.127255  acc: 93.0000%(15/16)
Batch[20] - loss: 0.051692  acc: 100.0000%(16/16)
Batch[21] - loss: 0.075525  acc: 100.0000%(16/16)
Batch[22] - loss: 0.127949  acc: 100.0000%(16/16)
Batch[23] - loss: 0.057746  acc: 100.0000%(16/16)
Batch[24] - loss: 0.045684  acc: 100.0000%(16/16)
Batch[25] - loss: 0.054996  acc: 100.0000%(16/16)
Batch[26] - loss: 0.067556  acc: 100.0000%(16/16)
Batch[27] - loss: 0.056483  acc: 100.0000%(16/16)
Batch[28] - loss: 0.038604  acc: 100.0000%(16/16)
Batch[29] - loss: 0.018175  acc: 100.0000%(16/16)
Batch[30] - loss: 0.101249  acc: 93.0000%(15/16)
Batch[31] - loss: 0.076578  acc: 100.0000%(16/16)
Batch[32] - loss: 0.065828  acc: 100.0000%(16/16)
Batch[33] - loss: 0.031990  acc: 100.0000%(16/16)
Batch[34] - loss: 0.020805  acc: 100.0000%(8/8)
Average loss:0.061045 average acc:99.000000%
Reload the best model...
0.00025
Val set acc: 0.8414634146341463
Best val set acc: 0.8414634146341463

Epoch  17 / 18
Batch[0] - loss: 0.100193  acc: 100.0000%(16/16)
Batch[1] - loss: 0.139478  acc: 100.0000%(16/16)
Batch[2] - loss: 0.074352  acc: 100.0000%(16/16)
Batch[3] - loss: 0.103020  acc: 100.0000%(16/16)
Batch[4] - loss: 0.150576  acc: 100.0000%(16/16)
Batch[5] - loss: 0.108696  acc: 100.0000%(16/16)
Batch[6] - loss: 0.108651  acc: 100.0000%(16/16)
Batch[7] - loss: 0.100772  acc: 100.0000%(16/16)
Batch[8] - loss: 0.142046  acc: 100.0000%(16/16)
Batch[9] - loss: 0.111645  acc: 100.0000%(16/16)
Batch[10] - loss: 0.058584  acc: 100.0000%(16/16)
Batch[11] - loss: 0.112978  acc: 100.0000%(16/16)
Batch[12] - loss: 0.089393  acc: 100.0000%(16/16)
Batch[13] - loss: 0.040603  acc: 100.0000%(16/16)
Batch[14] - loss: 0.193023  acc: 100.0000%(16/16)
Batch[15] - loss: 0.133521  acc: 100.0000%(16/16)
Batch[16] - loss: 0.107992  acc: 100.0000%(16/16)
Batch[17] - loss: 0.032329  acc: 100.0000%(16/16)
Batch[18] - loss: 0.053450  acc: 100.0000%(16/16)
Batch[19] - loss: 0.216524  acc: 100.0000%(16/16)
Batch[20] - loss: 0.066042  acc: 100.0000%(16/16)
Batch[21] - loss: 0.066194  acc: 100.0000%(16/16)
Batch[22] - loss: 0.037710  acc: 100.0000%(16/16)
Batch[23] - loss: 0.058906  acc: 100.0000%(16/16)
Batch[24] - loss: 0.117211  acc: 100.0000%(16/16)
Batch[25] - loss: 0.053012  acc: 100.0000%(16/16)
Batch[26] - loss: 0.072837  acc: 100.0000%(16/16)
Batch[27] - loss: 0.041597  acc: 100.0000%(16/16)
Batch[28] - loss: 0.099444  acc: 100.0000%(16/16)
Batch[29] - loss: 0.063399  acc: 100.0000%(16/16)
Batch[30] - loss: 0.062146  acc: 100.0000%(16/16)
Batch[31] - loss: 0.188673  acc: 100.0000%(16/16)
Batch[32] - loss: 0.122849  acc: 100.0000%(16/16)
Batch[33] - loss: 0.049967  acc: 100.0000%(16/16)
Batch[34] - loss: 0.088058  acc: 100.0000%(8/8)
Average loss:0.096168 average acc:100.000000%
Val set acc: 0.8292682926829268
Best val set acc: 0.8414634146341463

Epoch  18 / 18
Batch[0] - loss: 0.101026  acc: 100.0000%(16/16)
Batch[1] - loss: 0.064863  acc: 100.0000%(16/16)
Batch[2] - loss: 0.055687  acc: 100.0000%(16/16)
Batch[3] - loss: 0.062524  acc: 100.0000%(16/16)
Batch[4] - loss: 0.154698  acc: 93.0000%(15/16)
Batch[5] - loss: 0.083222  acc: 100.0000%(16/16)
Batch[6] - loss: 0.057799  acc: 100.0000%(16/16)
Batch[7] - loss: 0.128348  acc: 100.0000%(16/16)
Batch[8] - loss: 0.031825  acc: 100.0000%(16/16)
Batch[9] - loss: 0.147595  acc: 100.0000%(16/16)
Batch[10] - loss: 0.055315  acc: 100.0000%(16/16)
Batch[11] - loss: 0.102375  acc: 100.0000%(16/16)
Batch[12] - loss: 0.064278  acc: 100.0000%(16/16)
Batch[13] - loss: 0.173669  acc: 100.0000%(16/16)
Batch[14] - loss: 0.101550  acc: 100.0000%(16/16)
Batch[15] - loss: 0.073859  acc: 100.0000%(16/16)
Batch[16] - loss: 0.117684  acc: 100.0000%(16/16)
Batch[17] - loss: 0.083808  acc: 100.0000%(16/16)
Batch[18] - loss: 0.032770  acc: 100.0000%(16/16)
Batch[19] - loss: 0.067624  acc: 100.0000%(16/16)
Batch[20] - loss: 0.056548  acc: 100.0000%(16/16)
Batch[21] - loss: 0.167681  acc: 93.0000%(15/16)
Batch[22] - loss: 0.104952  acc: 93.0000%(15/16)
Batch[23] - loss: 0.017938  acc: 100.0000%(16/16)
Batch[24] - loss: 0.106945  acc: 100.0000%(16/16)
Batch[25] - loss: 0.165529  acc: 100.0000%(16/16)
Batch[26] - loss: 0.036963  acc: 100.0000%(16/16)
Batch[27] - loss: 0.088887  acc: 100.0000%(16/16)
Batch[28] - loss: 0.158692  acc: 100.0000%(16/16)
Batch[29] - loss: 0.085753  acc: 100.0000%(16/16)
Batch[30] - loss: 0.043576  acc: 100.0000%(16/16)
Batch[31] - loss: 0.072179  acc: 100.0000%(16/16)
Batch[32] - loss: 0.140568  acc: 100.0000%(16/16)
Batch[33] - loss: 0.063390  acc: 100.0000%(16/16)
Batch[34] - loss: 0.230400  acc: 100.0000%(8/8)
Average loss:0.094301 average acc:99.000000%
Val set acc: 0.8292682926829268
Best val set acc: 0.8414634146341463
================================
              precision    recall  f1-score   support

          NR      0.936     0.957     0.946        46
          FR      0.976     0.870     0.920        46
          TR      0.857     0.933     0.894        45
          UR      0.979     0.979     0.979        47

    accuracy                          0.935       184
   macro avg      0.937     0.935     0.935       184
weighted avg      0.938     0.935     0.935       184

